{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bfb526",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color='#053c96'><h2><center> Classically Punk</h2></center></font>\n",
    "<figure>\n",
    "<center><img src =\"https://images.unsplash.com/photo-1487180144351-b8472da7d491?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=872&q=80\" width = \"750\" height = '600' alt=\"Classical Punk\"/>\n",
    "<font size=\"0\" color='#053c96'><h4><center> Photo Credit: Unsplash</h4></center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8aca5",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color='#053c96'><b> Contributor</b></font>  \n",
    "<font size=\"+0\" ><b> Umar Kabir</b></font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c866556",
   "metadata": {},
   "source": [
    "<a id='table-of-contents'></a>\n",
    "[Table of Contents](#table-of-contents)\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "  * [Overview](#overview)\n",
    "  * [Problem Statement](#problem-statement)\n",
    "  * [Objectives](#goals)\n",
    "- [Importing Libraries](#importing-dependencies)\n",
    "- [Data](#data)\n",
    "- [Exploratory Data Analysis](#exploratory-data-analysis)\n",
    "  * [Data Exploration](#data-exploration)\n",
    "  * [Data Visualization](#data-visualization)\n",
    "  * [Summary Statistics](#summary-statistics)\n",
    "  * [Feature Correlation](#feature-correlation)\n",
    "- [Data Preparation](#data-preparation)\n",
    "  * [Data Cleaning](#data-cleaning)\n",
    "  * [Feature Engineering](#feature-engineering)\n",
    "  * [Data Transformation](#data-transformation)\n",
    "- [Modeling](#modeling)\n",
    "  * [Model Selection](#model-selection)\n",
    "  * [Model Training](#model-training)\n",
    "  * [Model Evaluation](#model-evaluation)\n",
    "  * [Hyperparameter Tuning](#hyperparameter-tuning)\n",
    "- [Results](#results)\n",
    "  * [Analysis Results](#analysis-results)\n",
    "  * [Model Performance](#model-performance)\n",
    "  * [Feature Importance](#feature-importance)\n",
    "  * [Implications](#implications)\n",
    "- [Conclusion](#conclusion)\n",
    "  * [Summary](#summary)\n",
    "  * [Limitations](#limitations)\n",
    "  * [Recommendations](#recommendations)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836292fd",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "<font size=\"+2\" color='#053c96'><b> 1. Introduction</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "Classically Punk is a music genre classification project that combines different elements of music to develop a machine learning model that predicts music genre.  \n",
    "\n",
    "In this project, we aim to use machine learning techniques to automatically classify different musical genres, from audio snippets. To achieve this, we will need to find a library that can read music files and extract features from them, such as tempo, pitch, and melody. We will then use these features to train a machine learning model that can classify different genres of music.  \n",
    "\n",
    "The deliverables for this project include a presentation with slides on how we classified the music, as well as assumptions, implications, and other important information, and code that the DevOps team can push to production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06537a61",
   "metadata": {},
   "source": [
    "<a id='overview'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 1.1 Overview</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "The project aims to develop a machine learning application that can automatically classify different musical genres from audio snippets. The main steps involved in the project include finding a library that can read music files and extract features from them, identifying relevant features for classification, and training a machine learning model to classify different genres of music. The project also involves handling large data sets and analyzing media files to generate data and identify patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a08599",
   "metadata": {},
   "source": [
    "<a id='problem-statement'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 1.2 Problem Statement</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "The problem statement for this project is the difficulty in manually classifying large collections of music into different genres. This process can be time-consuming and prone to errors, as it requires a deep understanding of the characteristics of each genre. Furthermore, as the amount of music available online continues to grow, it becomes increasingly challenging to keep up with the task of categorizing music by hand. The goal of this project is to develop a machine learning application that can automate the process of music classification, making it faster, more accurate, and scalable. The application will use features extracted from audio files to train a machine learning model that can classify different genres of music, including Classically Punk, without the need for human intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65055b3b",
   "metadata": {},
   "source": [
    "<a id='goals'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 1.3 Objectives</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "1. To identify a suitable library for reading music files and extracting features from them.\n",
    "2. To determine relevant features that can be used for music genre classification, such as tempo, pitch, and melody.\n",
    "3. To preprocess the audio data, such as removing noise and converting it into a format suitable for machine learning algorithms.\n",
    "4. To train a machine learning model on the audio data using a suitable algorithm, such as neural networks or decision trees.\n",
    "5. To evaluate the performance of the machine learning model using appropriate metrics, such as accuracy, precision, and recall.\n",
    "6. To optimize the model's performance by tuning hyperparameters and experimenting with different algorithms.\n",
    "7. To develop a user-friendly interface for the application that allows users to upload audio files and receive genre classification results.\n",
    "8. To present the results of the project, including the classification accuracy and the features that were most relevant for genre classification.\n",
    "9. To deliver code that can be easily deployed by the DevOps team for use in a production environment.\n",
    "10. - Speech activity detection: Speech activity detection is the task of identifying the segments of an audio signal that contain speech. This can be done by looking for changes in the energy of the signal, the zero crossing rate, or the pitch.\n",
    "- Speaker identification: Speaker identification is the task of identifying the speaker of an audio signal. This can be done by looking for features that are unique to each speaker, such as the vocal tract shape or the way that they pronounce certain words.\n",
    "- Music genre classification: Music genre classification is the task of classifying an audio signal into a particular genre of music. This can be done by looking for features that are commonly associated with different genres of music, such as the tempo, the pitch, or the rhythm.\n",
    "- Sound event detection: Sound event detection is the task of identifying the different types of sounds that are present in an audio signal. This can be done by looking for changes in the energy of the signal, the spectral content of the signal, or the temporal structure of the signal.\n",
    "- Automatic music transcription: Automatic music transcription is the task of converting an audio recording of music into a musical score. This can be done by looking for features that are associated with different musical notes, such as the pitch, the duration, and the timbre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c48e75",
   "metadata": {},
   "source": [
    "<a id='importing-dependencies'></a>\n",
    "<font size=\"+2\" color='#053c96'><b> 2. Importing Libraries</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70ac95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Insert the parent path relative to this notebook so we can import from the src folder.\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.dependencies import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a29aa",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "<font size=\"+2\" color='#053c96'><b> 3. Data</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "The dataset was used for the well-known paper in genre classification \"Musical genre classification of audio signals\" by G. Tzanetakis and P. Cook in IEEE Transactions on Audio and Speech Processing 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12d0496",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org.apache.spark.util does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Show the DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\sql\\readwriter.py:727\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:171\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 171\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:163\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    157\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PythonException(msg, stacktrace)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnknownException\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstackTrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacktrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:64\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[1;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackTrace \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     stackTrace\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stackTrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (SparkContext\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(origin))\n\u001b[0;32m     63\u001b[0m )\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(origin\u001b[38;5;241m.\u001b[39mgetCause())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:163\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    157\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PythonException(msg, stacktrace)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnknownException\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstackTrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacktrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:64\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[1;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackTrace \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     stackTrace\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stackTrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (SparkContext\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(origin))\n\u001b[0;32m     63\u001b[0m )\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcause\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(origin\u001b[38;5;241m.\u001b[39mgetCause())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:147\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkUpgradeException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m    146\u001b[0m c: Py4JJavaError \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mgetCause()\n\u001b[1;32m--> 147\u001b[0m stacktrace: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mUtils\u001b[38;5;241m.\u001b[39mexceptionString(e)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    149\u001b[0m     is_instance_of(gw, c, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.api.python.PythonException\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# To make sure this only catches Python UDFs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m ):\n\u001b[0;32m    157\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  An exception was thrown from the Python worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the stack trace below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c\u001b[38;5;241m.\u001b[39mgetMessage()\n\u001b[0;32m    160\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\java_gateway.py:1664\u001b[0m, in \u001b[0;36mJavaPackage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaClass(\n\u001b[0;32m   1662\u001b[0m         answer[proto\u001b[38;5;241m.\u001b[39mCLASS_FQN_START:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client)\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not exist in the JVM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(new_fqn))\n",
      "\u001b[1;31mPy4JError\u001b[0m: org.apache.spark.util does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read CSV Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file_path = '../data/data.csv'\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e871c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47144d6c",
   "metadata": {},
   "source": [
    "<a id='exploratory-data-analysis'></a>\n",
    "<font size=\"+2\" color='#053c96'><b> 4. Exploratory Data Anaysis</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b442d4",
   "metadata": {},
   "source": [
    "<a id='data-exploration'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 4.1 Data Exploration</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f477f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e12f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa452bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a1e0c",
   "metadata": {},
   "source": [
    "This function loads and plays an audio file of a specific genre and number using the librosa library. It takes two arguments, genre and num, which specify the genre of the audio and the number of the audio file within that genre, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('blues', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('classical', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('country', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('disco', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e740bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('hiphop', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('jazz', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75992ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('metal', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75714a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('pop', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('reggae', '00024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio('rock', '00024')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f4dd5",
   "metadata": {},
   "source": [
    "<a id='data-visualization'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 4.2 Data Visualization</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb346b1",
   "metadata": {},
   "source": [
    "This code generates a frequency bar chart of the 'Tempo' column in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(df, (pd.DatetimeIndex, pd.MultiIndex)):\n",
    "    df = df.to_frame(index=False)\n",
    "df = df.reset_index().drop('index', axis=1, errors='ignore')\n",
    "df.columns = [str(c) for c in df.columns]\n",
    "tempo_counts = df['Tempo'].value_counts().reset_index()\n",
    "tempo_counts.columns = ['Tempo', 'Frequency']\n",
    "tempo_counts = tempo_counts.sort_values(['Frequency', 'Tempo'], ascending=[False, True])\n",
    "tempo_counts = tempo_counts[:100]\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.barplot(x='Frequency', y='Tempo', data=tempo_counts)\n",
    "ax.set(xlabel='Frequency', ylabel='Tempo', title='Tempo Value Counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_waveform(x, num):\n",
    "    # Load WAV file\n",
    "    wav_file = f'/Users/umarkabir/Documents/Qwasar/Classical Punk/genres/{x}/{x}.{num}.wav'\n",
    "    y, sr = librosa.load(wav_file)\n",
    "# Create x-axis values\n",
    "    time = librosa.times_like(y, sr=sr)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.lineplot(x=time, y=y)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'Sample waveform for {x}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411d650",
   "metadata": {},
   "source": [
    "This function loads a WAV file of a specific genre and number, and generates a sample waveform plot using the librosa and plotly libraries. It takes two arguments, x and num, which specify the genre of the audio and the number of the audio file within that genre, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('blues', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957903dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('classical', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('country', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('disco', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876baecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('hiphop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a189dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('jazz', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('metal', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('pop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('reggae', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform('rock', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9306be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spectogram(x, num):\n",
    "    # Load audio file\n",
    "    audio_path = f'/Users/umarkabir/Documents/Qwasar/Classical Punk/genres/{x}/{x}.{num}.wav'\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Calculate spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "\n",
    "    # Convert to decibels\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    ax = sns.heatmap(S_dB, cmap='viridis')\n",
    "\n",
    "    # Set x and y axis labels\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "\n",
    "    # Set figure title\n",
    "    ax.set_title(f'Sample spectrogram for {x}')\n",
    "\n",
    "    # Show figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d5198",
   "metadata": {},
   "source": [
    "This function loads a WAV file of a specific genre and number, and generates a sample spectrogram plot using the librosa and plotly libraries. It takes two arguments, x and num, which specify the genre of the audio and the number of the audio file within that genre, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('blues', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6419f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('classical', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('country', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('disco', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('hiphop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb37527",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('jazz', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('metal', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('pop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('reggae', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectogram('rock', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def show_sr(x, num):\n",
    "    # Load audio file\n",
    "    audio_path = f'/Users/umarkabir/Documents/Qwasar/Classical Punk/genres/{x}/{x}.{num}.wav'\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute spectral rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "\n",
    "    # Create plot\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(spectral_rolloff, color='blue')\n",
    "    ax.set(title=f'Sample spectral rolloff for {x}', xlabel='Frame', ylabel='Frequency (Hz)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6796c",
   "metadata": {},
   "source": [
    "This function show_sr(x, num) loads an audio file and computes the spectral rolloff. It then creates a Plotly line plot of the spectral rolloff values with the x-axis representing the frame and the y-axis representing frequency in Hz. The title of the plot is set to \"Sample spectral rolloff for x\", where x is the name of the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57524963",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('blues', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('classical', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('country', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('disco', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('hiphop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d93428",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('jazz', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48545f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('metal', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('pop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('reggae', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9255df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr('rock', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f44e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_chroma(x, num):\n",
    "    # Load audio file\n",
    "    audio_path = f'/Users/umarkabir/Documents/Qwasar/Classical Punk/genres/{x}/{x}.{num}.wav'\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute chroma feature\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "    # Create time axis in seconds\n",
    "    time = librosa.frames_to_time(np.arange(chroma.shape[1]), sr=sr)\n",
    "\n",
    "    # Create chroma note names\n",
    "    chroma_note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(chroma, index=chroma_note_names, columns=time)\n",
    "\n",
    "    # Plot heatmap using seaborn\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df, cmap='viridis', xticklabels=50, yticklabels=1)\n",
    "    plt.title(f'Sample chroma feature for {x}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Chroma Note')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4e47c",
   "metadata": {},
   "source": [
    "This function takes in two arguments x and num representing the music genre and the song number, respectively. It then loads the corresponding audio file and computes the chroma feature using librosa's chroma_stft function. It creates a time axis in seconds using frames_to_time function, and chroma note names as a list. It then creates a heatmap trace using go.Heatmap with time as the x-axis, chroma_note_names as the y-axis, and chroma as the z-axis. Finally, it sets the layout with appropriate x and y axis titles, and a title for the figure. It shows the resulting figure using fig.show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('blues', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112da3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('classical', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0239bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('country', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ecfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('disco', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('hiphop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('jazz', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067380b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('metal', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52443761",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('pop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('reggae', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e07a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_chroma('rock', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_zcr(x, num):\n",
    "    # Load audio file\n",
    "    audio_path = f'/Users/umarkabir/Documents/Qwasar/Classical Punk/genres/{x}/{x}.{num}.wav'\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "\n",
    "    # Plot with Seaborn\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    sns.lineplot(data=zcr[0], ax=ax)\n",
    "    ax.set(title=f'Zero Crossing Rate for {x} Genre', xlabel='Time (s)', ylabel='ZCR')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85dd14",
   "metadata": {},
   "source": [
    "The show_zcr function takes in two arguments: x, which represents the genre of the music file, and num, which represents the number of the music file. It calculates the zero-crossing rate of the audio file and plots it using Plotly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('blues', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc43cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('classical', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ae409",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('country', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('disco', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('hiphop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b38f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('jazz', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('pop', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('reggae', '00090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e37627",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_zcr('rock', '00090')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642835c",
   "metadata": {},
   "source": [
    "<a id='summary-statistics'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 4.3 Summary Statistics</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd55d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_kurt(data, col):\n",
    "    # Calculate skewness and kurtosis of Income column\n",
    "    _skewness = skew(data[col])\n",
    "    _kurtosis = kurtosis(data[col])\n",
    "\n",
    "    # Create histogram of Income column with mean, median, and mode\n",
    "    sns.histplot(data=data, x=col, kde=True)\n",
    "    plt.axvline(data[col].mean(), color='r', linestyle='--', label='Mean')\n",
    "    plt.axvline(data[col].median(), color='g', linestyle='--', label='Median')\n",
    "    plt.axvline(data[col].mode()[0], color='b', linestyle='--', label='Mode')\n",
    "    plt.legend()\n",
    "\n",
    "    # Add text annotation for skewness and kurtosis values\n",
    "    plt.annotate('Skewness: {:.2f}'.format(_skewness), xy=(0.5, 0.9), xycoords='axes fraction')\n",
    "    plt.annotate('Kurtosis: {:.2f}'.format(_kurtosis), xy=(0.5, 0.85), xycoords='axes fraction')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f48ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'blues'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'classical'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'country'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3758ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'disco'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d668351",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'hiphop'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'jazz'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'metal'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'pop'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'reggae'], 'Tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_kurt(df[df['Genre'] == 'rock'], 'Tempo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea1afa",
   "metadata": {},
   "source": [
    "<a id='feature-correlation'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 4.4 Feature Correlation</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "\n",
    "# Set figure size and font sizes\n",
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "sns.set(font_scale=1.9)\n",
    "\n",
    "# Plot heatmap with adjusted color map\n",
    "sns.heatmap(df_corr, cmap='coolwarm', annot=True, center=0, square=True)\n",
    "\n",
    "# Adjust font size of features\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=35)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=35)\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Correlation Matrix', fontsize=30)\n",
    "plt.xlabel('Features', fontsize=20)\n",
    "plt.ylabel('Features', fontsize=20)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727a626",
   "metadata": {},
   "source": [
    "<a id='data-preparation'></a>\n",
    "<font size=\"+2\" color='#053c96'><b> 5. Data Preparation</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5fc006",
   "metadata": {},
   "source": [
    "<a id='data-cleaning'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 5.1 Data Cleaning</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab2b48",
   "metadata": {},
   "source": [
    "<a id='feature-engineering'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 5.2 Feature Engineering</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ce3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Beats Mean'] = df['Beats'].apply(lambda x: np.mean(x))\n",
    "df['Central Moments Mean'] = df['Central Moments'].apply(lambda x: np.mean(x))\n",
    "df['Zero Crossing Rate Mean'] = df['Zero Crossing Rate'].apply(lambda x: np.mean(x))\n",
    "df['RMSE Mean'] = df['RMSE'].apply(lambda x: np.mean(x))\n",
    "df['Spectral Contrast Mean'] = df['Spectral Contrast'].apply(lambda x: np.mean(x))\n",
    "df['Spectral Roll-off Mean'] = df['Spectral Roll-off'].apply(lambda x: np.mean(x))\n",
    "df['MFCC Mean'] = df['MFCC'].apply(lambda x: np.mean(x))\n",
    "df['Chroma Mean'] = df['Chroma'].apply(lambda x: np.mean(x))\n",
    "df['Spectral Centroid Mean'] = df['Spectral Centroid'].apply(lambda x: np.mean(x))\n",
    "df['Spectral Bandwidth Mean'] = df['Spectral Bandwidth'].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Beats Var'] = df['Beats'].apply(lambda x: np.var(x))\n",
    "df['Central Moments Var'] = df['Central Moments'].apply(lambda x: np.var(x))\n",
    "df['Zero Crossing Rate Var'] = df['Zero Crossing Rate'].apply(lambda x: np.var(x))\n",
    "df['RMSE Var'] = df['RMSE'].apply(lambda x: np.var(x))\n",
    "df['Spectral Contrast Var'] = df['Spectral Contrast'].apply(lambda x: np.var(x))\n",
    "df['Spectral Roll-off Var'] = df['Spectral Roll-off'].apply(lambda x: np.var(x))\n",
    "df['MFCC Var'] = df['MFCC'].apply(lambda x: np.var(x))\n",
    "df['Chroma Var'] = df['Chroma'].apply(lambda x: np.var(x))\n",
    "df['Spectral Centroid Var'] = df['Spectral Centroid'].apply(lambda x: np.var(x))\n",
    "df['Spectral Bandwidth Var'] = df['Spectral Bandwidth'].apply(lambda x: np.var(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Beats Std'] = df['Beats'].apply(lambda x: np.std(x))\n",
    "df['Central Moments Std'] = df['Central Moments'].apply(lambda x: np.std(x))\n",
    "df['Zero Crossing Rate Std'] = df['Zero Crossing Rate'].apply(lambda x: np.std(x))\n",
    "df['RMSE Std'] = df['RMSE'].apply(lambda x: np.std(x))\n",
    "df['Spectral Contrast Std'] = df['Spectral Contrast'].apply(lambda x: np.std(x))\n",
    "df['Spectral Roll-off Std'] = df['Spectral Roll-off'].apply(lambda x: np.std(x))\n",
    "df['MFCC Std'] = df['MFCC'].apply(lambda x: np.std(x))\n",
    "df['Chroma Std'] = df['Chroma'].apply(lambda x: np.std(x))\n",
    "df['Spectral Centroid Std'] = df['Spectral Centroid'].apply(lambda x: np.std(x))\n",
    "df['Spectral Bandwidth Std'] = df['Spectral Bandwidth'].apply(lambda x: np.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff5001",
   "metadata": {},
   "source": [
    "<a id='data-transformation'></a>\n",
    "<font size=\"+1\" color='#780404'><b> 5.3 Data Transformation</b></font>  \n",
    "[back to top](#table-of-contents)\n",
    "<a id='modeling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09402f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = df['Genre']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(genre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target dataset\n",
    "#y = df['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8952a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Genre', 'Filename', 'Unnamed: 0', 'Beats', 'SR',\n",
    "             'Central Moments', 'Zero Crossing Rate', 'RMSE',\n",
    "             'Spectral Contrast', 'Spectral Roll-off', 'MFCC',\n",
    "             'Chroma', 'Spectral Centroid', 'Spectral Bandwidth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a TF-IDF object instance\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pareto Principle Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.3,\n",
    "                                                    random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43353f",
   "metadata": {},
   "source": [
    "<a id='modeling'></a>\n",
    "\n",
    "<font size=\"+2\" color='#053c96'><b> 6. Modeling</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ddcd8",
   "metadata": {},
   "source": [
    "<a id='model-selection'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 6.1 Model Selection</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass Support Vector Machines (SVM)\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', OneVsRestClassifier(SVC(kernel='rbf', C=1, gamma='scale')))\n",
    "])\n",
    "\n",
    "# K-Means Clustering\n",
    "kmeans_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kmeans', KMeans(n_clusters=10))\n",
    "])\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Convolutional Neural Networks (CNNs)\n",
    "cnn_pipeline = Pipeline([\n",
    "    ('clf', Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Compile the CNN model\n",
    "cnn_pipeline.named_steps['clf'].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadadaf",
   "metadata": {},
   "source": [
    "<a id='model-training'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 6.2 Model Training</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM pipeline\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fit K-Means pipeline\n",
    "kmeans_pipeline.fit(X_train)\n",
    "\n",
    "# Fit KNN pipeline\n",
    "knn_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d33277",
   "metadata": {},
   "source": [
    "<a id='model-evaluation'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 6.3 Model Evaluation</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lists for performance metrics and confusion matrices\n",
    "f1_list = []\n",
    "pr_list = []\n",
    "rc_list = []\n",
    "acc_list = []\n",
    "cm_list = []\n",
    "\n",
    "# Evaluate additional models\n",
    "# evaluate the SVM pipeline\n",
    "\n",
    "y_pred_svm = svm_pipeline.predict(X_test)\n",
    "f1_list.append(f1_score(y_test, y_pred_svm, average='weighted'))\n",
    "pr_list.append(precision_score(y_test, y_pred_svm, average='weighted'))\n",
    "rc_list.append(recall_score(y_test, y_pred_svm, average='weighted'))\n",
    "acc_list.append(accuracy_score(y_test, y_pred_svm))\n",
    "cm_list.append(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# evaluate the K-Means pipeline\n",
    "y_pred_kmeans = kmeans_pipeline.predict(X_test)\n",
    "f1_list.append(f1_score(y_test, y_pred_kmeans, average='weighted'))\n",
    "pr_list.append(precision_score(y_test, y_pred_kmeans, average='weighted'))\n",
    "rc_list.append(recall_score(y_test, y_pred_kmeans, average='weighted'))\n",
    "acc_list.append(accuracy_score(y_test, y_pred_kmeans))\n",
    "cm_list.append(confusion_matrix(y_test, y_pred_kmeans))\n",
    "\n",
    "# evaluate the KNN pipeline\n",
    "y_pred_knn = knn_pipeline.predict(X_test)\n",
    "f1_list.append(f1_score(y_test, y_pred_knn, average='weighted'))\n",
    "pr_list.append(precision_score(y_test, y_pred_knn, average='weighted'))\n",
    "rc_list.append(recall_score(y_test, y_pred_knn, average='weighted'))\n",
    "acc_list.append(accuracy_score(y_test, y_pred_knn))\n",
    "cm_list.append(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# evaluate the CNN pipeline\n",
    "y_pred_cnn = cnn_pipeline.predict(X_test)\n",
    "f1_list.append(f1_score(y_test, y_pred_cnn, average='weighted'))\n",
    "pr_list.append(precision_score(y_test, y_pred_cnn, average='weighted'))\n",
    "rc_list.append(recall_score(y_test, y_pred_cnn, average='weighted'))\n",
    "acc_list.append(accuracy_score(y_test, y_pred_cnn))\n",
    "cm_list.append(confusion_matrix(y_test, y_pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['SVM', 'Kmeans', 'KNN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091e1e0",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "<font size=\"+2\" color='#053c96'><b> 7. Results</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a65abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Model': model_list, 'F1': f1_list, 'Precision': pr_list, 'Recall': rc_list, 'Accuracy': acc_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2626b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9d457",
   "metadata": {},
   "source": [
    "<a id='analysis-results'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 7.1 Analysis of Results</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "The results suggest that the SVM and KNN models perform better than the Kmeans model, based on F1-score, precision, recall, and accuracy.  \n",
    "\n",
    "Overall, the SVM and KNN models appear to be more suitable for this task than the Kmeans model. However, the performance of the models may depend on the specific characteristics of the dataset, and further analysis may be necessary to confirm the generalizability of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea103b",
   "metadata": {},
   "source": [
    "<a id='model-performance'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 7.2 Model Performance</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "From the given results, the SVM and KNN models perform better than the Kmeans model in terms of F1-score, precision, and recall. The SVM model has the highest F1-score and recall, while the KNN model has the highest precision. However, the SVM model has slightly lower precision than the KNN model.\n",
    "\n",
    "The Kmeans model has the lowest F1-score, precision, and recall among the three models, indicating that it performs poorly in predicting positive cases. Although the accuracy of the Kmeans model is the same as that of the SVM model, accuracy alone is not a reliable metric for imbalanced datasets where the majority class dominates the prediction.\n",
    "\n",
    "Therefore, based on the given results, the SVM and KNN models appear to be more suitable for the given task than the Kmeans model. However, it is important to note that the performance of the models may depend on the specific characteristics of the dataset, and further analysis may be necessary to confirm the generalizability of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b54eb5",
   "metadata": {},
   "source": [
    "<a id='implications'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 7.3 Implications</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "The given results have several implications, such as:\n",
    "\n",
    "Model Selection: The results suggest that the SVM and KNN models may be more suitable for this task than the Kmeans model. Therefore, the SVM or KNN model may be selected for further analysis or implementation.\n",
    "\n",
    "Hyperparameter Tuning: The performance of the models may depend on the hyperparameters chosen. Therefore, hyperparameter tuning can be performed to optimize the model performance.\n",
    "\n",
    "Dataset Characteristics: The performance of the models may depend on the specific characteristics of the dataset, such as the distribution of the classes or the presence of outliers. Therefore, further analysis may be necessary to confirm the generalizability of the models to other datasets.\n",
    "\n",
    "Performance Metrics: The selection of performance metrics can have implications for the evaluation of the models. For example, the accuracy metric may not be reliable for imbalanced datasets. Therefore, multiple metrics should be used to evaluate the models comprehensively.\n",
    "\n",
    "Overall, the given results provide insights into the performance of the models and can guide further analysis or implementation of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb8f75",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "\n",
    "<font size=\"+2\" color='#053c96'><b> 8. Conclusion</b></font>  \n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6ce88",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 8.1 Summary</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "In conclusion, the results of the machine learning models developed for music genre classification suggest that the SVM and KNN models perform better than the Kmeans model. Both the SVM and KNN models have higher F1-scores, precision, and recall than the Kmeans model, indicating better performance in predicting the different music genres, including Classically Punk. This implies that the developed machine learning application can automate the process of music genre classification, making it faster, more accurate, and scalable. The application can extract features from audio files and train an SVM or KNN model to classify music into different genres without the need for human intervention. However, further analysis is necessary to confirm the generalizability of the models to other datasets, and hyperparameter tuning may be required to optimize the performance of the models. Overall, the developed machine learning application has the potential to revolutionize the music industry by streamlining the process of music genre classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b300b",
   "metadata": {},
   "source": [
    "<a id='recommendations'></a>\n",
    "\n",
    "<font size=\"+1\" color='#780404'><b> 8.2 Recommendations</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "Based on the problem statement and the results obtained from the machine learning models, here are some recommendations that could help to further improve the music genre classification application:\n",
    "\n",
    "1. Data Augmentation: To improve the performance of the machine learning models, it may be helpful to augment the training data by adding variations of the existing data. This can be done by applying audio effects such as pitch shifting, time stretching, or adding noise to create a more diverse training set.\n",
    "\n",
    "2. Feature Engineering: Feature engineering involves selecting and extracting meaningful features from audio files to train the machine learning model. By experimenting with different audio features and selecting the most informative ones, the performance of the machine learning model can be improved.\n",
    "\n",
    "3. Ensemble Learning: Ensemble learning involves combining the predictions of multiple machine learning models to improve the overall performance. By training multiple models using different algorithms or hyperparameters and combining their predictions, the overall accuracy of the application can be improved.\n",
    "\n",
    "4. User Feedback: Collecting feedback from users of the application can help to improve the accuracy of the machine learning model over time. By allowing users to provide feedback on the accuracy of the classification results, the application can learn from its mistakes and continuously improve its performance.\n",
    "\n",
    "5. Continuous Monitoring: It is important to continuously monitor the performance of the machine learning model to ensure that it is accurately classifying the different music genres. Regularly updating the model with new data and retraining it can help to improve its accuracy and keep up with changes in the music industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342fdf5",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "\n",
    "<font size=\"+2\" color='#053c96'><b> 9. References</b></font>  \n",
    "[back to top](#table-of-contents)  \n",
    "\n",
    "1. Arsh Chowdhry. Music Genre Classification Using CNN. https://blog.clairvoyantsoft.com/music-genre-classification-using-cnn-ef9461553726\n",
    "2. Faisal Ahmed, Padma Polash Paul, Marina Gavrilova. Music Genre Classification Using a Gradient-Based Local Texture Descriptor https://www.researchgate.net/publication/303860385_Music_Genre_Classification_Using_a_Gradient-Based_Local_Texture_Descriptor\n",
    "3. Albert Jiménez. Music Genre Classification with Deep Learning https://github.com/jsalbert/Music-Genre-Classification-with-Deep-Learning\n",
    "4. Insiyah Hajoori. Music Genre Classification https://github.com/Insiyaa/Music-Genre-Classification\n",
    "5. A. Elbir, N. Aydin. Music genre classification and music recommendation by using deep learning https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/el.2019.4202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af53da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
